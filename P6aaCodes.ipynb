{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points à discuter avec Corentin:\n",
    "# 1. Méthodes à comparer :\n",
    "    # a) Méthode de traitement de texte (tf-idf-supervisée et une méthode non supervisée (par ex lda et lda vis)), et\n",
    "    # b) méthode de prédiction : rf seulement (XGBOOST ne gère pas quand y a n-dimensions)\n",
    "        # Alternative possible one vs rest (on entraîne un des Tags vs les autres)\n",
    "\n",
    "# Dans cet exercice : \n",
    "    # Approche supervisée = retrouver les tags \n",
    "    # Approche non supervisée = prévoir des tags. On ne passe pas par un dataset déjà crée : on crée un tag à partir du texte\n",
    "        # on peut utiliser : nmf (non negative matrice factorisation) : classement par topics (définis = clusters)\n",
    "        # lda (latent dirichlet allocation) : assez proche de nmf. \n",
    "        # Essayer ldavis qui permet de visualiser les topics générés par lda\n",
    "\n",
    "\n",
    "# 2. Elaboration base line (mesure performances) : J'ai réussi si je transforme y en table de 1 dimension\n",
    "    # Est ce ok de procéder comme tel pour la mesure de la perf ? etant entendu que pour la prédiction, je garde\n",
    "    # y en n-dimensions : ce qui a été choisi numpy.argmin() / numpy.argmax() ==> Sans ce cas pas vraiment le bon choix\n",
    "    # Sinon, comment on fait ?\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "# Multilabel\n",
    "# Accuracy : Compte le score comme OK, si on a prédit correctement l'ensemble des scores : assez conservatif\n",
    "# On peut se construire sa métrique\n",
    "# Proportion des tags prédits vs ceux à l'origine\n",
    "\n",
    "# 3. Output de la prédiction : un peu comme pour le projet de reco de ciné, on va chercher l'indice de la\n",
    "    # Questionnaire : on saisit le titre et le corps du texte\n",
    "    # En réponse, on obtient un ou plusieurs Tags Est ce bien cela ?\n",
    "\n",
    "# Pour suivre les modifications du code final à déployer, \n",
    "# utiliser un logiciel de gestion de versions, par exemple Git.\n",
    "# ==>  A mettre en place maintenant\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 1 : import librairie et données sources\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"P6QueryResults4.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3869 entries, 0 to 3868\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Id      3869 non-null   int64 \n",
      " 1   Body    3869 non-null   object\n",
      " 2   Title   3869 non-null   object\n",
      " 3   Tags    3869 non-null   object\n",
      " 4   Text    3869 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 151.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Etape 2 : Creation de la matière sur laquelle on va travailler\n",
    "\n",
    "# Rappel : L'objectif consiste à Prédire des Tags, sur la base :\n",
    "# Des champs 'Body' et 'Title' qui constituent la variable X\n",
    "# Du champs 'Tags' qui constitue la variable Y à prédire\n",
    "df['Text'] = df['Body'].astype(str) + df['Title'].astype(str)\n",
    "df['Tags'] = df['Tags'].astype(str)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 3 : Import librairie pour nettoyage texte et tf-idf\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des X et y\n",
    "X, y = df.Text, df.Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql server - equivalent excel choose function vb net\n",
      "free c++ memory vector arr\n"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;?*]')\n",
    "BAD_SYMBOLS_RE1 = re.compile('[^0-9a-z #+_-]')\n",
    "STOPWORDS = list((stopwords.words('english')))\n",
    "\n",
    "def text_prepare_WithSoup(text, join_symbol):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "\n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    # 1. Remove HTML\n",
    "    text = BeautifulSoup(text,features=\"lxml\").get_text()\n",
    "    \n",
    "    # lowercase text\n",
    "    text = text.lower()\n",
    "\n",
    "    # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, \" \", text,)\n",
    "\n",
    "    # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = re.sub(BAD_SYMBOLS_RE1, \" \", text)\n",
    "    text = re.sub(r'\\s+', \" \", text)\n",
    "\n",
    "    # delete stopwords from text\n",
    "    text = f'{join_symbol}'.join(\n",
    "        [i for i in text.split() if i not in STOPWORDS])\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "tests = [\"SQL Server - any equivalent of Excel's CHOOSE function VB.NET. ?\",\n",
    "         \"How to free c++ memory vector<int> * arr?\"]\n",
    "for test in tests:\n",
    "    print(text_prepare_WithSoup(test, ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql server - equivalent excel choose function vb.net.\n",
      "free c++ memory vector int arr\n"
     ]
    }
   ],
   "source": [
    "BAD_SYMBOLS_RE2 = re.compile('[^0-9a-z .#+_-]') # A la différence de 'BAD_SYMBOLS_RE2', ici, on garde le '.'\n",
    "# 'VB.NET' devient 'vb.net'\n",
    "def text_prepare_NoSoup(text, join_symbol):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "\n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    # lowercase text\n",
    "    text = text.lower()\n",
    "\n",
    "    # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, \" \", text,)\n",
    "\n",
    "    # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = re.sub(BAD_SYMBOLS_RE2, \" \", text)\n",
    "    text = re.sub(r'\\s+', \" \", text)\n",
    "\n",
    "    # delete stopwords from text\n",
    "    text = f'{join_symbol}'.join(\n",
    "        [i for i in text.split() if i not in STOPWORDS])\n",
    "\n",
    "    return text\n",
    "for test in tests:\n",
    "    print(text_prepare_NoSoup(test, ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = [text_prepare_WithSoup(X, ' ') for X in X]\n",
    "y_cleaned = [text_prepare_NoSoup(y, ' ') for y in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>I want to use a <code>Track-Bar</code> to change a <code>Form</code>\\'s opacity.</p>\\n<p>This is my code:</p>\\n<pre class=\"lang-cs prettyprint-override\"><code>decimal trans = trackBar1.Value / 5000;\\nthis.Opacity = trans;\\n</code></pre>\\n<p>When I build the application, it gives the following error:</p>\\n<blockquote>\\n<p>Cannot implicitly convert type <code>decimal</code> to <code>double</code></p>\\n</blockquote>\\n<p>I have tried using <code>trans</code> and <code>double</code> but then the <code>Control</code> doesn\\'t work. This code worked fine in a past VB.NET project.</p>\\nConvert Decimal to Double'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'want use track-bar change form opacity code decimal trans trackbar1 value 5000 opacity trans build application gives following error cannot implicitly convert type decimal double tried using trans double control work code worked fine past vb net project convert decimal double'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50                                  <c++><berkeley-db>\n",
       "51                                <svn><collaboration>\n",
       "52                     <c#><.net><sorting><dictionary>\n",
       "53            <sql><database><oracle><version-control>\n",
       "54                                     <security><php>\n",
       "55                     <c++><oop><class><nested-class>\n",
       "56                          <language-agnostic><types>\n",
       "57                                       <python><xml>\n",
       "58         <string><language-agnostic><cross-platform>\n",
       "59                                 <email><email-spam>\n",
       "60    <java><generics><warnings><casting><type-safety>\n",
       "61                                    <search><lucene>\n",
       "62                       <ios><objective-c><landscape>\n",
       "63                                          <com><vb6>\n",
       "64       <internet-explorer><windows-mobile><pocketpc>\n",
       "Name: Tags, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c++ berkeley-db',\n",
       " 'svn collaboration',\n",
       " 'c# .net sorting dictionary',\n",
       " 'sql database oracle version-control',\n",
       " 'security php',\n",
       " 'c++ oop class nested-class',\n",
       " 'language-agnostic types',\n",
       " 'python xml',\n",
       " 'string language-agnostic cross-platform',\n",
       " 'email email-spam',\n",
       " 'java generics warnings casting type-safety',\n",
       " 'search lucene',\n",
       " 'ios objective-c landscape',\n",
       " 'com vb6',\n",
       " 'internet-explorer windows-mobile pocketpc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cleaned [50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 5 : Conversion des données textuelles et valeur numériques\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_x = CountVectorizer(analyzer=\"word\",\n",
    "                             max_features=1500,\n",
    "                             # min_df=0.05,\n",
    "                             max_df=0.9,\n",
    "                             stop_words=stopwords.words('english'),\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             )\n",
    "            \n",
    "X = vectorizer_x.fit_transform(X_cleaned).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On obtient les noms colonnes variable X\n",
    "ColName_X = list(vectorizer_x.vocabulary_.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_y = CountVectorizer(analyzer=\"word\",\n",
    "                             max_features=50,\n",
    "                             # min_df=0.05,\n",
    "                             max_df=0.85,\n",
    "                             stop_words=stopwords.words('english'),\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             )\n",
    "\n",
    "y=vectorizer_y.fit_transform(y_cleaned).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On obtient les noms colonnes variable y\n",
    "ColName_y = list(vectorizer_y.vocabulary_.keys())[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2005', '2008', 'agnostic', 'algorithm', 'apache', 'asp', 'build', 'control', 'css', 'data', 'database', 'design', 'file', 'html', 'interface', 'java', 'javascript', 'jquery', 'language', 'linq', 'linux', 'macos', 'multithreading', 'mvc', 'mysql', 'net', 'oop', 'performance', 'php', 'python', 'regex', 'ruby', 'security', 'server', 'services', 'sql', 'string', 'studio', 'svn', 'testing', 'unit', 'user', 'vb', 'version', 'visual', 'web', 'windows', 'winforms', 'wpf', 'xml']\n"
     ]
    }
   ],
   "source": [
    "tfidf_vocab_y = vectorizer_y.get_feature_names()\n",
    "print(tfidf_vocab_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3869, 1500)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3869, 50)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 6 : Process TF-IDF\n",
    "# 6.1 Pour X\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3869, 1500)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3869, 50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 7 : Mise en place des ensemble train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 1500)\n",
      "(1161, 1500)\n",
      "(2708, 50)\n",
      "(1161, 50)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 8 : Entrainement classification des textes et prédiction des tags\n",
    "# Préalablement, on fait un GridSearchCV pour recherche paramètres à optimiser\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "param_gridRF = {\"max_depth\": [3, 5],  # Maximum number of levels in tree\n",
    "                \"min_samples_split\": [3, 10],# Minimum number of samples required to split a node\n",
    "                }\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV : La fonction RF fonctionne, mais pas les fonctions de calcul de perf.\n",
    "# modelrfc = GridSearchCV(rfc,\n",
    "                       # param_gridRF,\n",
    "                       # n_jobs=-1,\n",
    "                       # cv=5\n",
    "                       # )\n",
    "# modelrf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(modelrfc.best_params_)\n",
    "# Pas de raison que le grid search ne fonctionne pas pour un y n-dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=5, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prédiction sur la base des meilleurs paramètres\n",
    "classifier = RandomForestClassifier(max_depth = 5, min_samples_split = 10)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1161, 50)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prédiction modèle y = 1 dimension pour obtenir les performances\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# On va se créer notre propre fonction de calcul de perf\n",
    "# Est ce que les deux y_pred et y_tests sont identiques ?\n",
    "comparaison = y_pred == y_test\n",
    "equal_arrays = comparaison.all()\n",
    "print(equal_arrays)\n",
    "# La réponse est non, ce qui est une bonne nouvelle !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0321619293712317\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# Moyenne des différences\n",
    "y_dif_mean = np.mean(y_test - y_pred)\n",
    "# On a une différence moyenne de 3%, ce qui implique que la prédiction est assez juste\n",
    "print(y_dif_mean)\n",
    "print(y_dif_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1161, 50)\n"
     ]
    }
   ],
   "source": [
    "y_diff = np.subtract(y_test,y_pred)\n",
    "print(y_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19222410468812415"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STd dev des difference\n",
    "np.std(y_test - y_pred)\n",
    "# On a une erreur moyenne de 20 %, ce qui implique une variation très grande des types d'erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essayer d'établir une matrice de confusion ou une sorte d'équivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f1_score(y_test, y_pred)) # Devrait accepter y n-dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Etape 9 : Evaluation du modèle : NE FONCTIONNE PAS\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# print(confusion_matrix(y_test,y_pred))\n",
    "# print(classification_report(y_test,y_pred))\n",
    "# print(accuracy_score(y_test, y_pred)) # Devrait accepter y n-dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** ICI *** Effectuer methode BERT et comparer avec TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 10 : Méthode non supervisée, création de clusters de tags par méthode non supervisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1 Clusters via K-mean\n",
    "from sklearn.cluster import KMeans\n",
    "# Perform k-means clustering\n",
    "num_clusters = 30\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "# Use k-keans to make sentiment label clustering\n",
    "kmeans.fit(y)\n",
    "# get cluster assignments; a label (0 or 1) for each review\n",
    "labels = kmeans.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original \n",
    "sorted_index_centroids = kmeans.cluster_centers_.argsort()[:,::-1]\n",
    "\n",
    "# ***ICI\n",
    "# Pourquoi est ce vide ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 words: testing, unit, net, language, agnostic,\n",
      "\n",
      "Cluster 1 words: algorithm, macos, apache, xml, web,\n",
      "\n",
      "Cluster 2 words: net, winforms, windows, wpf, services,\n",
      "\n",
      "Cluster 3 words: sql, server, database, net, services,\n",
      "\n",
      "Cluster 4 words: net, visual, studio, asp, vb,\n",
      "\n",
      "Cluster 5 words: java, xml, string, windows, regex,\n",
      "\n",
      "Cluster 6 words: php, mysql, oop, performance, apache,\n",
      "\n",
      "Cluster 7 words: python, linux, xml, windows, macos,\n",
      "\n",
      "Cluster 8 words: asp, net, javascript, web, services,\n",
      "\n",
      "Cluster 9 words: ruby, windows, string, mysql, design,\n",
      "\n",
      "Cluster 10 words: database, sql, mysql, design, performance,\n",
      "\n",
      "Cluster 11 words: sql, server, 2005, database, 2008,\n",
      "\n",
      "Cluster 12 words: language, agnostic, algorithm, regex, oop,\n",
      "\n",
      "Cluster 13 words: linq, sql, net, asp, database,\n",
      "\n",
      "Cluster 14 words: windows, file, svn, linux, server,\n",
      "\n",
      "Cluster 15 words: net, asp, mvc, testing, html,\n",
      "\n",
      "Cluster 16 words: svn, version, control, visual, database,\n",
      "\n",
      "Cluster 17 words: data, algorithm, database, wpf, xml,\n",
      "\n",
      "Cluster 18 words: javascript, jquery, html, css, web,\n",
      "\n",
      "Cluster 19 words: user, interface, winforms, net, wpf,\n",
      "\n",
      "Cluster 20 words: net, vb, winforms, file, sql,\n",
      "\n",
      "Cluster 21 words: visual, studio, 2008, windows, build,\n",
      "\n",
      "Cluster 22 words: net, asp, mvc, javascript, unit,\n",
      "\n",
      "Cluster 23 words: linux, security, file, php, mysql,\n",
      "\n",
      "Cluster 24 words: sql, mysql, services, php, design,\n",
      "\n",
      "Cluster 25 words: html, css, javascript, user, regex,\n",
      "\n",
      "Cluster 26 words: svn, build, net, php, server,\n",
      "\n",
      "Cluster 27 words: version, control, visual, macos, database,\n",
      "\n",
      "Cluster 28 words: visual, studio, 2008, 2005, net,\n",
      "\n",
      "Cluster 29 words: net, asp, vb, linq, performance,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in range(num_clusters):\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    # replace 10 with n words per cluster\n",
    "    for ind in sorted_index_centroids[i, :5]:\n",
    "        print(' %s' % tfidf_vocab_y[ind].split(' ')[0], end=',')\n",
    "    print()  # add whitespace\n",
    "    print()  # add whitespace\n",
    "\n",
    "# 2020 08 31 - Cluster à améliorer - source = clean_train_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.2 Cluster via LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-0f1752d7e310>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-0f1752d7e310>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    En attente\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "En attente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenant que l'on a les paramètres optimaux et une baseline, on va exécuter le modèle\n",
    "# mais avec y en n-dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prédiction sur la base des meilleurs paramètres\n",
    "modelrf = RandomForestClassifier(max_depth=5, min_samples_split=10)\n",
    "modelrf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction modèle y = 1 dimension pour obtenir les performances\n",
    "y_pred_rf = modelrf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 10 : Sauvegarde du modèle devra être adapté si BERT = meilleur\n",
    "with open('P6text_classifier', 'wb') as picklefile:\n",
    "    pickle.dump(modelrf,picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 11 : Chargement du modèle pour prédire les tags et évaluer sa performance\n",
    "with open('P6text_classifier', 'rb') as training_model:\n",
    "    model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
